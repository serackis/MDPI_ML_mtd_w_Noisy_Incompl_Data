\relax 
\providecommand\hyper@newdestlabel[2]{}
\providecommand\zref@newlabel[2]{}
\bibstyle{Definitions/mdpi}
\providecommand\HyperFirstAtBeginDocument{\AtBeginDocument}
\HyperFirstAtBeginDocument{\ifx\hyper@anchor\@undefined
\global\let\oldcontentsline\contentsline
\gdef\contentsline#1#2#3#4{\oldcontentsline{#1}{#2}{#3}}
\global\let\oldnewlabel\newlabel
\gdef\newlabel#1#2{\newlabelxx{#1}#2}
\gdef\newlabelxx#1#2#3#4#5#6{\oldnewlabel{#1}{{#2}{#3}}}
\AtEndDocument{\ifx\hyper@anchor\@undefined
\let\contentsline\oldcontentsline
\let\newlabel\oldnewlabel
\fi}
\fi}
\global\let\hyper@last\relax 
\gdef\HyperFirstAtBeginDocument#1{#1}
\providecommand\HyField@AuxAddToFields[1]{}
\providecommand\HyField@AuxAddToCoFields[2]{}
\citation{martiSpeakerLocalizationDetection2011,lopatka_detection_2016,valinLocalizationSimultaneousMoving2004}
\citation{bruttiComparisonDifferentSound2008,wengThreedimensionalSoundLocalization2001,awad-allaTwostageApproachPassive2020}
\citation{valinRobust3DLocalization2006}
\citation{4959563}
\citation{dibiaseHighaccuracyLowlatencyTechnique2000}
\citation{silvermanPerformanceRealtimeSourcelocation2005a}
\citation{martiSpeakerLocalizationDetection2011}
\@writefile{toc}{\contentsline {section}{\numberline {1}Introduction}{1}{section.1}\protected@file@percent }
\citation{laufer-goldshteinSemiSupervisedSoundSource2016}
\citation{heDeepNeuralNetworks2018b,heAdaptationMultipleSound2019,adavanneDirectionArrivalEstimation2017}
\@writefile{toc}{\contentsline {section}{\numberline {2}Materials and Methods}{2}{section.2}\protected@file@percent }
\citation{dibiaseHighaccuracyLowlatencyTechnique2000,scheiblerPyroomacousticsPythonPackage2018a}
\@writefile{toc}{\contentsline {subsection}{\numberline {2.1}Acoustic Features}{3}{subsection.2.1}\protected@file@percent }
\@writefile{toc}{\contentsline {subsubsection}{\numberline {2.1.1}Time Difference of Arrival}{3}{subsubsection.2.1.1}\protected@file@percent }
\@writefile{toc}{\contentsline {subsubsection}{\numberline {2.1.2}Room Impulse Response and Room Transfer Function}{3}{subsubsection.2.1.2}\protected@file@percent }
\@writefile{toc}{\contentsline {subsubsection}{\numberline {2.1.3}Steered Response Power}{3}{subsubsection.2.1.3}\protected@file@percent }
\@writefile{toc}{\contentsline {subsubsection}{\numberline {2.1.4}Properties of acoustic features}{3}{subsubsection.2.1.4}\protected@file@percent }
\@writefile{toc}{\contentsline {subsection}{\numberline {2.2}Acoustic feature acquisition}{3}{subsection.2.2}\protected@file@percent }
\@writefile{toc}{\contentsline {subsubsection}{\numberline {2.2.1}Unlabeled dataset}{4}{subsubsection.2.2.1}\protected@file@percent }
\newlabel{eq:unlabeled_src_max_speed}{{1}{4}{Unlabeled dataset}{equation.2.1}{}}
\@writefile{toc}{\contentsline {subsubsection}{\numberline {2.2.2}Labeled dataset}{4}{subsubsection.2.2.2}\protected@file@percent }
\@writefile{toc}{\contentsline {subsection}{\numberline {2.3}Audio signal framing}{4}{subsection.2.3}\protected@file@percent }
\@writefile{toc}{\contentsline {subsection}{\numberline {2.4}\ensuremath  {\text  {SRP-PHAT}}{} feature acquisition}{4}{subsection.2.4}\protected@file@percent }
\@writefile{toc}{\contentsline {subsection}{\numberline {2.5}Acoustic features selection (thresholding)}{4}{subsection.2.5}\protected@file@percent }
\citation{pedregosaScikitlearnMachineLearning2011}
\@writefile{toc}{\contentsline {subsubsection}{\numberline {2.5.1}Training/testing dataset split}{5}{subsubsection.2.5.1}\protected@file@percent }
\@writefile{toc}{\contentsline {subsection}{\numberline {2.6}Acoustic manifold embedding learning}{5}{subsection.2.6}\protected@file@percent }
\@writefile{toc}{\contentsline {subsubsection}{\numberline {2.6.1}\ensuremath  {{\mathrm  {ISOMAP}}}{} embedding}{5}{subsubsection.2.6.1}\protected@file@percent }
\@writefile{toc}{\contentsline {subsection}{\numberline {2.7}Graph dataset}{5}{subsection.2.7}\protected@file@percent }
\newlabel{subsec:graphdataset}{{2.7}{5}{Graph dataset}{subsection.2.7}{}}
\@writefile{toc}{\contentsline {subsubsection}{\numberline {2.7.1}Dataset preprocessing}{5}{subsubsection.2.7.1}\protected@file@percent }
\@writefile{toc}{\contentsline {subsubsection}{\numberline {2.7.2}Affinity matrix calculation}{5}{subsubsection.2.7.2}\protected@file@percent }
\citation{}
\@writefile{toc}{\contentsline {subsubsection}{\numberline {2.7.3}Neighbor samples and neighbor sample weights}{6}{subsubsection.2.7.3}\protected@file@percent }
\@writefile{toc}{\contentsline {subsubsection}{\numberline {2.7.4}Labeled/unlabeled sample marking}{6}{subsubsection.2.7.4}\protected@file@percent }
\@writefile{toc}{\contentsline {subsubsection}{\numberline {2.7.5}Labeled samples repetition}{6}{subsubsection.2.7.5}\protected@file@percent }
\@writefile{toc}{\contentsline {subsection}{\numberline {2.8}Graph-Regularized Neural Network}{6}{subsection.2.8}\protected@file@percent }
\@writefile{toc}{\contentsline {subsubsection}{\numberline {2.8.1}Neural network}{6}{subsubsection.2.8.1}\protected@file@percent }
\@writefile{lof}{\contentsline {figure}{\numberline {1}{\ignorespaces General architecture of a graph regularized neural network (considering 4 neighbor features). $ x_0 $ is the main input feature, $ x_{1..4} $ are neighbor input features, $ a_{1..4} $ are corresponding neighbor input feature weights, $ y_0 $ is the target feature, $ m $ is the labeled/unlabeled flag, $ \mathaccentV {hat}45E{y}_0 $ is the label prediction for main input feature, $ \mathaccentV {hat}45E{y}_{1..4} $ are the label predictions for the neighbor input features\relax }}{7}{figure.caption.1}\protected@file@percent }
\providecommand*\caption@xref[2]{\@setref\relax\@undefined{#1}}
\newlabel{fig:networktraining}{{1}{7}{General architecture of a graph regularized neural network (considering 4 neighbor features). $ x_0 $ is the main input feature, $ x_{1..4} $ are neighbor input features, $ a_{1..4} $ are corresponding neighbor input feature weights, $ y_0 $ is the target feature, $ m $ is the labeled/unlabeled flag, $ \hat {y}_0 $ is the label prediction for main input feature, $ \hat {y}_{1..4} $ are the label predictions for the neighbor input features\relax }{figure.caption.1}{}}
\@writefile{lot}{\contentsline {table}{\numberline {1}{\ignorespaces Table of neural network architectures used in for the experimentation\relax }}{7}{table.caption.2}\protected@file@percent }
\@writefile{toc}{\contentsline {subsubsection}{\numberline {2.8.2}Architecture}{7}{subsubsection.2.8.2}\protected@file@percent }
\@writefile{toc}{\contentsline {subsubsection}{\numberline {2.8.3}Loss function}{7}{subsubsection.2.8.3}\protected@file@percent }
\newlabel{eq:grnn_loss_function}{{4}{7}{Loss function}{equation.2.4}{}}
\citation{carlettaAMIMeetingCorpus2006}
\@writefile{toc}{\contentsline {subsection}{\numberline {2.9}Experimental setup}{8}{subsection.2.9}\protected@file@percent }
\@writefile{toc}{\contentsline {subsubsection}{\numberline {2.9.1}Enclosure}{8}{subsubsection.2.9.1}\protected@file@percent }
\@writefile{lof}{\contentsline {figure}{\numberline {2}{\ignorespaces The geometry of the acoustic enclosure used for real-world{} dataset collection and labeled sound source positions; height of the enclosure was \SI {3.75}{\m }\relax }}{8}{figure.caption.3}\protected@file@percent }
\newlabel{fig:room_src_pos}{{2}{8}{The geometry of the acoustic enclosure used for \realworld {} dataset collection and labeled sound source positions; height of the enclosure was \SI {3.75}{\m }\relax }{figure.caption.3}{}}
\@writefile{toc}{\contentsline {subsubsection}{\numberline {2.9.2}Sound source}{8}{subsubsection.2.9.2}\protected@file@percent }
\@writefile{toc}{\contentsline {paragraph}{\numberline {2.9.2.1}Source signal}{8}{paragraph.2.9.2.1}\protected@file@percent }
\@writefile{toc}{\contentsline {paragraph}{\numberline {2.9.2.2}Source positions}{8}{paragraph.2.9.2.2}\protected@file@percent }
\@writefile{toc}{\contentsline {subsubsection}{\numberline {2.9.3}Unlabeled audio dataset}{8}{subsubsection.2.9.3}\protected@file@percent }
\citation{scheiblerPyroomacousticsPythonPackage2018a}
\citation{dibiaseHighaccuracyLowlatencyTechnique2000}
\citation{pedregosaScikitlearnMachineLearning2011}
\@writefile{toc}{\contentsline {subsubsection}{\numberline {2.9.4}Microphone arrays}{9}{subsubsection.2.9.4}\protected@file@percent }
\@writefile{toc}{\contentsline {subsubsection}{\numberline {2.9.5}Acoustic feature acquisition}{9}{subsubsection.2.9.5}\protected@file@percent }
\@writefile{toc}{\contentsline {subsubsection}{\numberline {2.9.6}Acoustic feature selection}{9}{subsubsection.2.9.6}\protected@file@percent }
\@writefile{toc}{\contentsline {subsubsection}{\numberline {2.9.7}Acoustic feature manifold learning}{9}{subsubsection.2.9.7}\protected@file@percent }
\@writefile{toc}{\contentsline {subsubsection}{\numberline {2.9.8}Dataset construction}{9}{subsubsection.2.9.8}\protected@file@percent }
\@writefile{toc}{\contentsline {subsubsection}{\numberline {2.9.9}\ensuremath  {\mathrm  {GRNN}}{} training}{9}{subsubsection.2.9.9}\protected@file@percent }
\@writefile{toc}{\contentsline {section}{\numberline {3}Results}{9}{section.3}\protected@file@percent }
\@writefile{lof}{\contentsline {figure}{\numberline {3}{\ignorespaces Dependency between the source position prediction, source \ensuremath  {\text  {DoA}}{} estimation and radial estimation RMSE and the acoustic feature thresholding level; linear regression model showed in solid line\relax }}{10}{figure.caption.4}\protected@file@percent }
\newlabel{fig:rmsethrmeanlvl}{{3}{10}{Dependency between the source position prediction, source \doa {} estimation and radial estimation RMSE and the acoustic feature thresholding level; linear regression model showed in solid line\relax }{figure.caption.4}{}}
\@writefile{lof}{\contentsline {subfigure}{\numberline{(a)}{\ignorespaces {position error}}}{10}{figure.caption.4}\protected@file@percent }
\@writefile{lof}{\contentsline {subfigure}{\numberline{(b)}{\ignorespaces {angular error}}}{10}{figure.caption.4}\protected@file@percent }
\@writefile{lof}{\contentsline {subfigure}{\numberline{(c)}{\ignorespaces {radial error}}}{10}{figure.caption.4}\protected@file@percent }
\@writefile{lof}{\contentsline {figure}{\numberline {4}{\ignorespaces Dependency between the source position prediction, source \ensuremath  {\text  {DoA}}{} estimation and radial estimation RMSE and the number of nearest neighbors considered for \ensuremath  {{\mathrm  {ISOMAP}}}{} embedding; linear regression model showed in solid line\relax }}{10}{figure.caption.5}\protected@file@percent }
\newlabel{fig:rmsenneighbors}{{4}{10}{Dependency between the source position prediction, source \doa {} estimation and radial estimation RMSE and the number of nearest neighbors considered for \isomap {} embedding; linear regression model showed in solid line\relax }{figure.caption.5}{}}
\@writefile{lof}{\contentsline {subfigure}{\numberline{(a)}{\ignorespaces {position error}}}{10}{figure.caption.5}\protected@file@percent }
\@writefile{lof}{\contentsline {subfigure}{\numberline{(b)}{\ignorespaces {angular error}}}{10}{figure.caption.5}\protected@file@percent }
\@writefile{lof}{\contentsline {subfigure}{\numberline{(c)}{\ignorespaces {radial error}}}{10}{figure.caption.5}\protected@file@percent }
\@writefile{lof}{\contentsline {figure}{\numberline {5}{\ignorespaces Dependency between the source position prediction, source \ensuremath  {\text  {DoA}}{} estimation and radial estimation RMSE and the number of nearest graph neighbors considered during the training dataset construction; $ 2^{\mathrm  {nd}} $ order regression model showed in solid line\relax }}{10}{figure.caption.6}\protected@file@percent }
\newlabel{fig:rmsengnbrs}{{5}{10}{Dependency between the source position prediction, source \doa {} estimation and radial estimation RMSE and the number of nearest graph neighbors considered during the training dataset construction; $ 2^{\mathrm {nd}} $ order regression model showed in solid line\relax }{figure.caption.6}{}}
\@writefile{lof}{\contentsline {subfigure}{\numberline{(a)}{\ignorespaces {position error}}}{10}{figure.caption.6}\protected@file@percent }
\@writefile{lof}{\contentsline {subfigure}{\numberline{(b)}{\ignorespaces {angular error}}}{10}{figure.caption.6}\protected@file@percent }
\@writefile{lof}{\contentsline {subfigure}{\numberline{(c)}{\ignorespaces {radial error}}}{10}{figure.caption.6}\protected@file@percent }
\@writefile{lof}{\contentsline {figure}{\numberline {6}{\ignorespaces Dependency between the source position prediction, source \ensuremath  {\text  {DoA}}{} estimation and radial estimation RMSE and the labeled samples repetition rate during \ensuremath  {\mathrm  {GRNN}}{} training; linear regression model showed in solid line\relax }}{11}{figure.caption.7}\protected@file@percent }
\newlabel{fig:rmsekrep}{{6}{11}{Dependency between the source position prediction, source \doa {} estimation and radial estimation RMSE and the labeled samples repetition rate during \grnn {} training; linear regression model showed in solid line\relax }{figure.caption.7}{}}
\@writefile{lof}{\contentsline {subfigure}{\numberline{(a)}{\ignorespaces {position error}}}{11}{figure.caption.7}\protected@file@percent }
\@writefile{lof}{\contentsline {subfigure}{\numberline{(b)}{\ignorespaces {angular error}}}{11}{figure.caption.7}\protected@file@percent }
\@writefile{lof}{\contentsline {subfigure}{\numberline{(c)}{\ignorespaces {radial error}}}{11}{figure.caption.7}\protected@file@percent }
\@writefile{lof}{\contentsline {figure}{\numberline {7}{\ignorespaces Dependency between the source position prediction, source \ensuremath  {\text  {DoA}}{} estimation and radial estimation RMSE and the ratio between the supervised and unsupervised loses considered during the \ensuremath  {\mathrm  {GRNN}}{} training; linear regression model showed in solid line\relax }}{11}{figure.caption.8}\protected@file@percent }
\newlabel{fig:rmsemu}{{7}{11}{Dependency between the source position prediction, source \doa {} estimation and radial estimation RMSE and the ratio between the supervised and unsupervised loses considered during the \grnn {} training; linear regression model showed in solid line\relax }{figure.caption.8}{}}
\@writefile{lof}{\contentsline {subfigure}{\numberline{(a)}{\ignorespaces {position error}}}{11}{figure.caption.8}\protected@file@percent }
\@writefile{lof}{\contentsline {subfigure}{\numberline{(b)}{\ignorespaces {angular error}}}{11}{figure.caption.8}\protected@file@percent }
\@writefile{lof}{\contentsline {subfigure}{\numberline{(c)}{\ignorespaces {radial error}}}{11}{figure.caption.8}\protected@file@percent }
\@writefile{lof}{\contentsline {figure}{\numberline {8}{\ignorespaces Dependency between the source position prediction, source \ensuremath  {\text  {DoA}}{} estimation and radial estimation RMSE and the \ensuremath  {\mathrm  {GRNN}}{} training sample batch size; linear regression model showed in solid line\relax }}{11}{figure.caption.9}\protected@file@percent }
\newlabel{fig:rmsebatchsize}{{8}{11}{Dependency between the source position prediction, source \doa {} estimation and radial estimation RMSE and the \grnn {} training sample batch size; linear regression model showed in solid line\relax }{figure.caption.9}{}}
\@writefile{lof}{\contentsline {subfigure}{\numberline{(a)}{\ignorespaces {position error}}}{11}{figure.caption.9}\protected@file@percent }
\@writefile{lof}{\contentsline {subfigure}{\numberline{(b)}{\ignorespaces {angular error}}}{11}{figure.caption.9}\protected@file@percent }
\@writefile{lof}{\contentsline {subfigure}{\numberline{(c)}{\ignorespaces {radial error}}}{11}{figure.caption.9}\protected@file@percent }
\@writefile{toc}{\contentsline {section}{\numberline {4}Discussion}{11}{section.4}\protected@file@percent }
\newlabel{fig:trirealspeechsrpdoathrrms1p02framedur0p05}{{9(a)}{12}{Subfigure 9(a)}{subfigure.9.1}{}}
\newlabel{sub@fig:trirealspeechsrpdoathrrms1p02framedur0p05}{{(a)}{12}{Subfigure 9(a)\relax }{subfigure.9.1}{}}
\newlabel{fig:trirealspeechsrpdoathrrms1p02framedur0p05err}{{9(b)}{12}{Subfigure 9(b)}{subfigure.9.2}{}}
\newlabel{sub@fig:trirealspeechsrpdoathrrms1p02framedur0p05err}{{(b)}{12}{Subfigure 9(b)\relax }{subfigure.9.2}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {9}{\ignorespaces Results of real-world speech source localization using geometric localization algorithm\relax }}{12}{figure.caption.10}\protected@file@percent }
\@writefile{lof}{\contentsline {subfigure}{\numberline{(a)}{\ignorespaces {lines represent the \ensuremath {\text {DoA}}{} radii of each array}}}{12}{figure.caption.10}\protected@file@percent }
\@writefile{lof}{\contentsline {subfigure}{\numberline{(b)}{\ignorespaces {lines represent localization error}}}{12}{figure.caption.10}\protected@file@percent }
\@writefile{lof}{\contentsline {figure}{\numberline {10}{\ignorespaces Predicted source positions using the intensity map approach\relax }}{12}{figure.caption.11}\protected@file@percent }
\newlabel{fig:imprediction}{{10}{12}{Predicted source positions using the intensity map approach\relax }{figure.caption.11}{}}
\@writefile{lof}{\contentsline {subfigure}{\numberline{(a)}{\ignorespaces {source positions is the argument of the intensity map}}}{12}{figure.caption.11}\protected@file@percent }
\@writefile{lof}{\contentsline {subfigure}{\numberline{(b)}{\ignorespaces {source positions is the location of the most prominent local peak of the intensity map}}}{12}{figure.caption.11}\protected@file@percent }
\@writefile{lof}{\contentsline {figure}{\numberline {11}{\ignorespaces 2-dimensional \ensuremath  {{\mathrm  {ISOMAP}}}{} embeddings of the \ensuremath  {\text  {SRP-PHAT}}{} features of the real-world unlabeled speech signal; point hue represents its\relax }}{12}{figure.caption.12}\protected@file@percent }
\newlabel{fig:realspeechisomapframedur0p05}{{11}{12}{2-dimensional \isomap {} embeddings of the \srpphat {} features of the real-world unlabeled speech signal; point hue represents its\relax }{figure.caption.12}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {12}{\ignorespaces Prediction of sound source position using a GRNN trained for 50 epochs.\relax }}{13}{figure.caption.13}\protected@file@percent }
\newlabel{fig:grnnpredictionsrealspeecharch350epochsframedur0p05}{{12}{13}{Prediction of sound source position using a GRNN trained for 50 epochs.\relax }{figure.caption.13}{}}
\@writefile{lot}{\contentsline {table}{\numberline {2}{\ignorespaces Summary of source location prediction errors for different localization methods\relax }}{13}{table.caption.14}\protected@file@percent }
\newlabel{table:methodsprederr}{{2}{13}{Summary of source location prediction errors for different localization methods\relax }{table.caption.14}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {13}{\ignorespaces The distributions of the prediction errors for different source localization methods\relax }}{13}{figure.caption.15}\protected@file@percent }
\newlabel{fig:1prederrdistribution}{{13}{13}{The distributions of the prediction errors for different source localization methods\relax }{figure.caption.15}{}}
\bibdata{SS_AS_MDPI_ASC}
\bibcite{martiSpeakerLocalizationDetection2011}{{1}{}{{Marti \em  {et~al.}}}{{Marti, Cobos, Aguilera, and Lopez}}}
\bibcite{lopatka_detection_2016}{{2}{}{{Lopatka \em  {et~al.}}}{{Lopatka, Kotus, and Czyzewski}}}
\bibcite{valinLocalizationSimultaneousMoving2004}{{3}{}{{Valin \em  {et~al.}}}{{Valin, Michaud, Hadjou, and Rouat}}}
\bibcite{bruttiComparisonDifferentSound2008}{{4}{}{{Brutti \em  {et~al.}}}{{Brutti, Omologo, and Svaizer}}}
\@writefile{toc}{\contentsline {section}{\numberline {5}Conclusions}{14}{section.5}\protected@file@percent }
\@writefile{toc}{\contentsline {section}{References}{14}{section.5}\protected@file@percent }
\bibcite{wengThreedimensionalSoundLocalization2001}{{5}{}{{Weng and Guentchev}}{{}}}
\bibcite{awad-allaTwostageApproachPassive2020}{{6}{2020/ed}{{Awad-Alla \em  {et~al.}}}{{Awad-Alla, Hamdy, Tolbah, Shahin, and Abdelaziz}}}
\bibcite{valinRobust3DLocalization2006}{{7}{}{{Valin \em  {et~al.}}}{{Valin, Michaud, and Rouat}}}
\bibcite{4959563}{{8}{}{{Lombard \em  {et~al.}}}{{Lombard, Rosenkranz, Buchner, and Kellermann}}}
\bibcite{silvermanPerformanceRealtimeSourcelocation2005a}{{9}{}{{Silverman \em  {et~al.}}}{{Silverman, Yu, Sachar, and Patterson}}}
\bibcite{laufer-goldshteinSemiSupervisedSoundSource2016}{{10}{}{{Laufer-Goldshtein \em  {et~al.}}}{{Laufer-Goldshtein, Talmon, and Gannot}}}
\bibcite{heDeepNeuralNetworks2018b}{{11}{}{{He \em  {et~al.}}}{{He, Motlicek, and Odobez}}}
\bibcite{heAdaptationMultipleSound2019}{{12}{}{{He \em  {et~al.}}}{{He, Motlicek, and Odobez}}}
\bibcite{adavanneDirectionArrivalEstimation2017}{{13}{}{{Adavanne \em  {et~al.}}}{{Adavanne, Politis, and Virtanen}}}
\bibcite{scheiblerPyroomacousticsPythonPackage2018a}{{14}{}{{Scheibler \em  {et~al.}}}{{Scheibler, Bezzam, and Dokmanić}}}
\bibcite{pedregosaScikitlearnMachineLearning2011}{{15}{}{{Pedregosa \em  {et~al.}}}{{Pedregosa, Varoquaux, Gramfort, Michel, Thirion, Grisel, Blondel, Prettenhofer, Weiss, Dubourg, Vanderplas, Passos, Cournapeau, Brucher, Perrot, and Duchesnay}}}
\bibcite{carlettaAMIMeetingCorpus2006}{{16}{}{{Carletta \em  {et~al.}}}{{Carletta, , and {others}}}}
\newlabel{LastPage}{{}{15}{}{page.15}{}}
\xdef\lastpage@lastpage{15}
\xdef\lastpage@lastpageHy{15}
\expandafter\ifx\csname c@page@totc\endcsname\relax\newcounter{page@totc}\fi\setcounter{page@totc}{16}
